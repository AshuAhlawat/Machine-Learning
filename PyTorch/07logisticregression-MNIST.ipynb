{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashua\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "# DATASET DOWNLOAD\n",
    "#dataset = torchvision.datasets.MNIST(root=\"./data\", train=True, download=True, transform=torchvision.transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataset.Subset"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds, val_ds = torch.utils.data.random_split(dataset, [50000, 10000])\n",
    "\n",
    "print(len(train_ds), len(val_ds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size)\n",
    "val_dl = DataLoader(val_ds, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 784]) torch.Size([10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0194,  0.0319,  0.0357,  ...,  0.0130, -0.0153,  0.0258],\n",
       "         [-0.0199, -0.0257, -0.0349,  ...,  0.0053,  0.0055,  0.0214],\n",
       "         [-0.0061,  0.0021, -0.0293,  ..., -0.0231,  0.0332,  0.0060],\n",
       "         ...,\n",
       "         [-0.0228,  0.0357,  0.0330,  ..., -0.0348,  0.0201, -0.0230],\n",
       "         [ 0.0176,  0.0059,  0.0241,  ..., -0.0212,  0.0346,  0.0204],\n",
       "         [-0.0039,  0.0188, -0.0255,  ..., -0.0243, -0.0028, -0.0080]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0055, -0.0251, -0.0303, -0.0007, -0.0226, -0.0210, -0.0090, -0.0056,\n",
       "         -0.0182,  0.0085], requires_grad=True)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = 28*28\n",
    "num_classes = 10\n",
    "\n",
    "class MnistModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(input_size, num_classes)\n",
    "        \n",
    "    def forward(self, image):\n",
    "        image = image.reshape(-1,784)\n",
    "        return self.linear(image)\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)\n",
    "        loss = torch.nn.functional.cross_entropy(out, labels) \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                    \n",
    "        loss = torch.nn.functional.cross_entropy(out, labels)   \n",
    "        acc = accuracy(out, labels)           \n",
    "        return {'loss': loss, 'accuracy': acc}\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()\n",
    "        batch_accuracy = [x['accuracy'] for x in outputs]\n",
    "        epoch_accuracy = torch.stack(batch_accuracy).mean()\n",
    "        return {'loss': epoch_loss.item(), 'accuracy': epoch_accuracy.item()}\n",
    "        \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], loss: {:.4f}, accuracy: {:.4f}\".format(epoch, result['loss'], result['accuracy']))\n",
    "        \n",
    "model = MnistModel()    \n",
    "\n",
    "print(model.linear.weight.shape,model.linear.bias.shape)\n",
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "for images, label in train_dl:\n",
    "    print(images.shape)\n",
    "    outputs = model(images)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0800)\n"
     ]
    }
   ],
   "source": [
    "def accuracy(outputs, label):\n",
    "    preds = torch.max(outputs, dim=1)\n",
    "\n",
    "    return (sum(preds[1] == label)/ len(label))\n",
    "\n",
    "print(accuracy(outputs,label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    history = [] \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        result = evaluate(model, val_loader)\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader):\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.301473379135132, 'accuracy': 0.10029999911785126}\n"
     ]
    }
   ],
   "source": [
    "result0 = evaluate(model, val_dl)\n",
    "print(result0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], loss: 1.8642, accuracy: 0.6398\n",
      "Epoch [1], loss: 1.5652, accuracy: 0.7357\n",
      "Epoch [2], loss: 1.3576, accuracy: 0.7731\n"
     ]
    }
   ],
   "source": [
    "history1 = fit(3, 0.001, model, train_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0595, -1.3121,  0.4483, -0.5267,  0.9997, -0.2762,  0.1878,  0.3818,\n",
      "          0.1153,  0.6561]], grad_fn=<AddmmBackward>)\n",
      "tensor([4])\n",
      "tensor([0.9997], grad_fn=<MaxBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "test_dataset = torchvision.datasets.MNIST(root=\"./data\", train=False)\n",
    "\n",
    "x=4\n",
    "\n",
    "\n",
    "img, label = test_dataset[x]\n",
    "img.resize((280,280)).show()\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root=\"./data\", train=False, transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "def predict_image(img, model):\n",
    "    xb = img.unsqueeze(0)\n",
    "    yb = model(xb)\n",
    "    print(yb)\n",
    "    _, preds = torch.max(yb, dim=1)\n",
    "    print(preds)\n",
    "    print(_)\n",
    "    return preds[0].item()\n",
    "\n",
    "img, label = test_dataset[x]\n",
    "predict_image(img, model)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2f97e602bf3efd1202fb41503b5059ddd336053f3958a92ca7b4a7a1e22459bb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
