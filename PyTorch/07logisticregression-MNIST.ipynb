{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\r\n",
    "import torchvision"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "dataset = torchvision.datasets.MNIST(root=\"./data\", train=True, download=True, transform=torchvision.transforms.ToTensor())\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\ashua\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "train_ds, val_ds = torch.utils.data.random_split(dataset, [50000, 10000])\r\n",
    "\r\n",
    "print(len(train_ds), len(val_ds))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "50000 10000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from torch.utils.data.dataloader import DataLoader\r\n",
    "\r\n",
    "batch_size = 100\r\n",
    "\r\n",
    "train_dl = DataLoader(train_ds, batch_size)\r\n",
    "val_dl = DataLoader(val_ds, batch_size)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "input_size = 28*28\r\n",
    "num_classes = 10\r\n",
    "\r\n",
    "class MnistModel(torch.nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super().__init__()\r\n",
    "        self.linear = torch.nn.Linear(input_size, num_classes)\r\n",
    "        \r\n",
    "    def forward(self, image):\r\n",
    "        image = image.reshape(-1,784)\r\n",
    "        return self.linear(image)\r\n",
    "    \r\n",
    "    def training_step(self, batch):\r\n",
    "        images, labels = batch \r\n",
    "        out = self(images)\r\n",
    "        loss = torch.nn.functional.cross_entropy(out, labels) \r\n",
    "        return loss\r\n",
    "\r\n",
    "    def validation_step(self, batch):\r\n",
    "        images, labels = batch \r\n",
    "        out = self(images)                    \r\n",
    "        loss = torch.nn.functional.cross_entropy(out, labels)   \r\n",
    "        acc = accuracy(out, labels)           \r\n",
    "        return {'loss': loss, 'accuracy': acc}\r\n",
    "    \r\n",
    "    def validation_epoch_end(self, outputs):\r\n",
    "        batch_losses = [x['loss'] for x in outputs]\r\n",
    "        epoch_loss = torch.stack(batch_losses).mean()\r\n",
    "        batch_accuracy = [x['accuracy'] for x in outputs]\r\n",
    "        epoch_accuracy = torch.stack(batch_accuracy).mean()\r\n",
    "        return {'loss': epoch_loss.item(), 'accuracy': epoch_accuracy.item()}\r\n",
    "        \r\n",
    "    def epoch_end(self, epoch, result):\r\n",
    "        print(\"Epoch [{}], loss: {:.4f}, accuracy: {:.4f}\".format(epoch, result['loss'], result['accuracy']))\r\n",
    "        \r\n",
    "model = MnistModel()    \r\n",
    "\r\n",
    "print(model.linear.weight.shape,model.linear.bias.shape)\r\n",
    "list(model.parameters())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([10, 784]) torch.Size([10])\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 1.8717e-02,  2.5655e-02, -1.9281e-02,  ...,  2.4196e-02,\n",
       "           1.9529e-03,  2.8096e-02],\n",
       "         [ 4.6633e-05, -2.3835e-02, -1.8433e-02,  ...,  1.5085e-03,\n",
       "          -2.3998e-02, -1.8777e-02],\n",
       "         [ 3.3685e-02,  3.4502e-02, -4.9997e-03,  ..., -2.4566e-02,\n",
       "          -2.5581e-03, -1.0365e-02],\n",
       "         ...,\n",
       "         [-2.7373e-02, -1.1421e-04, -5.2387e-03,  ...,  3.1517e-03,\n",
       "          -2.6222e-02, -2.6995e-02],\n",
       "         [-1.0259e-02,  2.9644e-02, -2.3885e-02,  ...,  3.4910e-02,\n",
       "           5.7488e-03, -4.7861e-03],\n",
       "         [-1.1815e-02, -1.0367e-03,  9.9360e-03,  ...,  3.2132e-02,\n",
       "           2.4086e-02, -2.8986e-02]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0206,  0.0100,  0.0062,  0.0055, -0.0080,  0.0185,  0.0026,  0.0139,\n",
       "          0.0039,  0.0258], requires_grad=True)]"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "for images, label in train_dl:\r\n",
    "    print(images.shape)\r\n",
    "    outputs = model(images)\r\n",
    "    break"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([100, 1, 28, 28])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def accuracy(outputs, label):\r\n",
    "    preds = torch.max(outputs, dim=1)\r\n",
    "\r\n",
    "    return (sum(preds[1] == label)/ len(label))\r\n",
    "\r\n",
    "print(accuracy(outputs,label))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(0.2000)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\r\n",
    "    optimizer = opt_func(model.parameters(), lr)\r\n",
    "    history = [] \r\n",
    "    \r\n",
    "    for epoch in range(epochs):\r\n",
    "        \r\n",
    "        for batch in train_loader:\r\n",
    "            loss = model.training_step(batch)\r\n",
    "            \r\n",
    "            loss.backward()\r\n",
    "            \r\n",
    "            optimizer.step()\r\n",
    "            optimizer.zero_grad()\r\n",
    "        \r\n",
    "        result = evaluate(model, val_loader)\r\n",
    "        model.epoch_end(epoch, result)\r\n",
    "        history.append(result)\r\n",
    "\r\n",
    "    return history"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def evaluate(model, val_loader):\r\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\r\n",
    "    return model.validation_epoch_end(outputs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "result0 = evaluate(model, val_dl)\r\n",
    "print(result0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "history1 = fit(3, 0.001, model, train_dl, val_dl)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from PIL import Image\r\n",
    "test_dataset = torchvision.datasets.MNIST(root=\"./data\", train=False)\r\n",
    "\r\n",
    "x=9\r\n",
    "\r\n",
    "\r\n",
    "img, label = test_dataset[x]\r\n",
    "img.resize((280,280)).show()\r\n",
    "\r\n",
    "test_dataset = torchvision.datasets.MNIST(root=\"./data\", train=False, transform=torchvision.transforms.ToTensor())\r\n",
    "\r\n",
    "def predict_image(img, model):\r\n",
    "    xb = img.unsqueeze(0)\r\n",
    "    yb = model(xb)\r\n",
    "    _, preds = torch.max(yb, dim=1)\r\n",
    "    return preds[0].item()\r\n",
    "\r\n",
    "img, label = test_dataset[x]\r\n",
    "predict_image(img, model)\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 192
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.1",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit"
  },
  "interpreter": {
   "hash": "2f97e602bf3efd1202fb41503b5059ddd336053f3958a92ca7b4a7a1e22459bb"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}