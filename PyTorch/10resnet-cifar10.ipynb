{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "orig_nbformat": 4,
    "language_info": {
      "name": "python",
      "version": "3.9.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.5 64-bit"
    },
    "interpreter": {
      "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
    },
    "colab": {
      "name": "10resnet-cifar10.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount(\"/content/drive\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "metadata": {
        "id": "hl360K9tiVpS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9650d64e-7d3b-46ad-b425-17b9e1509f1e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# import tarfile\n",
        "\n",
        "# with tarfile.open('/content/drive/MyDrive/cifar10.tgz', 'r:gz') as tar:\n",
        "#     tar.extractall(path=\"\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "ztEf6CwGi8z-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "import torchvision.transforms as tfms\n",
        "\n",
        "mean = (0.4914, 0.4822, 0.4465)\n",
        "dev = (0.247, 0.2435, 0.2616)\n",
        "\n",
        "train_tfms = tfms.Compose([\n",
        "    tfms.RandomHorizontalFlip(),\n",
        "    tfms.RandomCrop(32,padding=4,padding_mode=\"reflect\"),\n",
        "    tfms.ToTensor(),\n",
        "    tfms.Normalize(mean,dev)\n",
        "])\n",
        "\n",
        "test_tfms = tfms.Compose([\n",
        "    tfms.ToTensor(),\n",
        "    tfms.Normalize(mean,dev)\n",
        "])"
      ],
      "outputs": [],
      "metadata": {
        "id": "UmaN4FD6iPLa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "root = \"./data/cifar10/\"\n",
        "\n",
        "train_ds = ImageFolder(root+\"train\",train_tfms)\n",
        "test_ds = ImageFolder(root+\"test\",test_tfms)\n",
        "\n",
        "img_cls = train_ds.classes\n",
        "print(img_cls)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEFZdHrJiPLd",
        "outputId": "43d1e613-af17-41bf-b18c-2f5f79a1fd3b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "from torch.utils.data.dataloader import DataLoader\n",
        "\n",
        "train_dl = DataLoader(train_ds,200,shuffle=True,num_workers=2, pin_memory=True)\n",
        "test_dl = DataLoader(test_ds,500,shuffle=True,num_workers=2, pin_memory=True)\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "e1e1AFwPiPLe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "\n",
        "# fig = plt.figure(figsize=(20,20))\n",
        "# grid = ImageGrid(fig,111,(10,10))\n",
        "\n",
        "\n",
        "# for images,labels in train_dl:\n",
        "#     image_arr = images.permute(0,2,3,1)\n",
        "\n",
        "#     for axis,image in zip(grid,image_arr):\n",
        "#         axis.imshow(image)\n",
        "#     plt.show()\n",
        "#     break"
      ],
      "outputs": [],
      "metadata": {
        "id": "EJYS30R5iPLf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "metadata": {
        "id": "E9RbhCmMUIqH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bb7472d-77b9-4788-9138-f768e36aef61"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "class ResNet12(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.norm15 = nn.BatchNorm2d(15)\n",
        "        self.norm30 = nn.BatchNorm2d(30)\n",
        "        self.norm60 = nn.BatchNorm2d(60)\n",
        "        self.norm120 = nn.BatchNorm2d(120)\n",
        "        self.norm200 = nn.BatchNorm2d(200)\n",
        "        self.norm360 = nn.BatchNorm2d(360)\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(3,15,kernel_size=3,stride=1,padding=1)\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(15,30,kernel_size=3,stride=1,padding=1)\n",
        "        \n",
        "        self.conv3 = nn.Conv2d(30,60,kernel_size=3,stride=2,padding=1)\n",
        "        \n",
        "        self.res1 = nn.Conv2d(60,120,kernel_size=1,stride=1,padding=0)\n",
        "        self.conv4 = nn.Conv2d(60,120,kernel_size=3,stride=1,padding=1)\n",
        "        \n",
        "        self.res2 = nn.Conv2d(120,200,kernel_size=1,stride=2,padding=0)\n",
        "        self.conv5 = nn.Conv2d(120,200,kernel_size=3,stride=2,padding=1)\n",
        "        self.res3 = nn.Conv2d(200,200,kernel_size=1,stride=1,padding=0)\n",
        "        self.conv6 = nn.Conv2d(200,200,kernel_size=3,stride=1,padding=1)\n",
        "        self.conv7 = nn.Conv2d(200,200,kernel_size=3,stride=1,padding=1)\n",
        "        self.conv7b = nn.Conv2d(200,200,kernel_size=3,stride=1,padding=1)\n",
        "        \n",
        "        self.res4 = nn.Conv2d(200,360,kernel_size=1,stride=2,padding=0)\n",
        "        self.conv8 = nn.Conv2d(200,360,kernel_size=3,stride=2,padding=1)\n",
        "        self.res5 = nn.Conv2d(360,360,kernel_size=1,stride=1,padding=0)\n",
        "        self.conv9 = nn.Conv2d(360,360,kernel_size=3,stride=1,padding=1)\n",
        "        self.conv10 = nn.Conv2d(360,360,kernel_size=3,stride=1,padding=1)\n",
        "        self.conv10b = nn.Conv2d(360,360,kernel_size=3,stride=1,padding=1)\n",
        "        \n",
        "        \n",
        "        self.pool = nn.MaxPool2d(2,2)\n",
        "        self.avgpool = nn.AvgPool2d(2,2)\n",
        "        self.flat = nn.Flatten()\n",
        "        \n",
        "        self.linear = nn.Linear(360,10)\n",
        "    \n",
        "\n",
        "    def forward(self, data):\n",
        "        # data 3 32 32\n",
        "\n",
        "        out = torch.relu(self.norm15(self.conv1(data)))#15 32 32\n",
        "        out = torch.relu(self.norm30(self.conv2(out)))#30 32 32\n",
        "        \n",
        "        out = torch.relu(self.norm60(self.conv3(out)))#60 16 16\n",
        "        x = self.res1(out)#120 16 16\n",
        "        out = torch.relu(self.norm120(self.conv4(out) + x))#120 16 16\n",
        "        \n",
        "        x = self.res2(out)#200 8 8\n",
        "        out = torch.relu(self.norm200(self.conv5(out) + x))#200 8 8\n",
        "        out = torch.relu(self.conv6(out))#200 8 8\n",
        "        out = torch.relu(self.conv7(out) + x)#200 8 8\n",
        "        out = torch.relu(self.conv7b(out))#200 8 8\n",
        "        \n",
        "        x = self.res4(out)#360 4 4\n",
        "        out = torch.relu(self.norm360(self.conv8(out) + x))#360 4 4\n",
        "        out = torch.relu(self.conv9(out))#360 4 4\n",
        "        out = torch.relu(self.conv10(out)+x)#360 4 4 \n",
        "        out = torch.relu(self.conv10b(out))#360 4 4 \n",
        "        \n",
        "        \n",
        "        out = self.avgpool(out)#360 2 2\n",
        "        out = self.avgpool(out)#360 1 1\n",
        "        \n",
        "        out = self.flat(out)#360\n",
        "        out = self.linear(out)#10\n",
        "        \n",
        "        out = torch.softmax(out,dim=-1)\n",
        "        \n",
        "        return out"
      ],
      "outputs": [],
      "metadata": {
        "id": "qJZM7heOiPLf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "Cifar10model = ResNet12().to(device)\n",
        "loss_fn = nn.BCELoss()\n",
        "opt = torch.optim.Adam(Cifar10model.parameters(),lr=0.001)\n",
        "# opt = torch.optim.SGD(Cifar10model.parameters(),lr=0.075)"
      ],
      "outputs": [],
      "metadata": {
        "id": "9dDqZ_UQiPLg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "import numpy as np\n",
        "\n",
        "def fit(epochs):\n",
        "    for epoch in range(epochs):\n",
        "        print(\"Epoch: \",epoch+1)\n",
        "\n",
        "        for images,labels in train_dl:\n",
        "            preds = Cifar10model(images.to(device))\n",
        "\n",
        "            targets = []\n",
        "            for label in labels:\n",
        "                x = np.zeros(10)\n",
        "                x[int(label)] = 1\n",
        "                targets.append(x.astype(np.float32))\n",
        "\n",
        "            targets = torch.tensor(targets)\n",
        "\n",
        "            loss = loss_fn(preds.to(device), targets.to(device))\n",
        "            loss.backward()\n",
        "            \n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "\n",
        "        print(\"Loss: \",round(loss.item(),6))\n",
        "\n",
        "        with torch.no_grad():\n",
        "            correct = 0\n",
        "            for images,labels in test_dl:\n",
        "                preds = Cifar10model(images.to(device))\n",
        "\n",
        "                for i in range(len(preds)):\n",
        "                    if (preds[i].max()==preds[i][labels[i].item()]):\n",
        "                        correct += 1\n",
        "            \n",
        "            acc = correct/len(test_ds)\n",
        "            print(\"Accuracy: \",round(acc*100,3))\n",
        "            print(\"\")\n",
        "        if acc>0.88:\n",
        "            break\n",
        "\n",
        "# fit(50)"
      ],
      "outputs": [],
      "metadata": {
        "id": "Wc_Q_uufiPLh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57b10e39-7c7f-4620-c055-a20356bf2921"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# from fastai.train import Learner\n",
        "# from fastai.metrics import accuracy\n",
        "# from fastai.basic_data import DataBunch\n",
        "\n",
        "# data = DataBunch.create(train_ds, test_ds, 200, path=root)\n",
        "# learner = Learner(data, Cifar10model, loss_func=nn.CrossEntropyLoss(),metrics = [accuracy])\n",
        "# learner.clip = 0.1"
      ],
      "outputs": [],
      "metadata": {
        "id": "o-D9CMQVfz5l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# learner.lr_find()\n",
        "# learner.recorder.plot()\n",
        "# learner.fit_one_cycle(3,1e-3,wd=1e-4)"
      ],
      "outputs": [],
      "metadata": {
        "id": "Cs0rfxSWihTs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# torch.save(Cifar10model.state_dict(),\"/content/drive/MyDrive/Cifar10ResNet12.pth\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "KF95xfJRdyGp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "#loading 88% accurate model data trained in 20 epochs on colab gpu's\n",
        "\n",
        "model = ResNet12()\n",
        "try:\n",
        "    if torch.cuda.is_available():\n",
        "        model.load_state_dict(torch.load(\"./saved_models/Cifar10ResNet12.pth\"))\n",
        "        print(\"Model Loaded(GPU)\")\n",
        "    else:\n",
        "        model.load_state_dict(torch.load(\"./saved_models/Cifar10ResNet12.pth\",map_location=torch.device(\"cpu\")))\n",
        "        print(\"Model Loaded(CPU)\")\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "    print(\"Error Occured in loading saved weights, training for new weights\")\n",
        "    # fit(20)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Loaded(CPU)\n"
          ]
        }
      ],
      "metadata": {
        "id": "JXM4TtSKiPLi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def predict(path,model):\n",
        "    img = Image.open(path)\n",
        "    \n",
        "    if img.size != (32,32):\n",
        "        img = img.resize((32,32))\n",
        "    \n",
        "    img_arr = np.asarray(img)\n",
        "    plt.imshow(img_arr)\n",
        "    \n",
        "    img_arr = img_arr/255\n",
        "    img_tsr = torch.Tensor([img_arr])\n",
        "    img_tsr = img_tsr.permute(0,3,1,2)\n",
        "    \n",
        "    print(img_tsr.shape)\n",
        "    \n",
        "    # pred = model(img_tsr).detach()\n",
        "    # pred = np.array(pred[0])\n",
        "    # pred_index = np.where(pred==max(pred))[0][0]\n",
        "    \n",
        "    # print(\"Prediction: \",img_cls[pred_index])\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "R5H1VMHQXDV1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "source": [
        "predict(\"./data/cifar10/test/bird/0002.png\",model)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnidentifiedImageError",
          "evalue": "cannot identify image file './data/cifar10/test/bird/0002.png'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_20453/2337431835.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./data/cifar10/test/bird/0002.png\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipykernel_20453/2709643461.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(path, model)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   2956\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmessage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maccept_warnings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2957\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2958\u001b[0;31m     raise UnidentifiedImageError(\n\u001b[0m\u001b[1;32m   2959\u001b[0m         \u001b[0;34m\"cannot identify image file %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2960\u001b[0m     )\n",
            "\u001b[0;31mUnidentifiedImageError\u001b[0m: cannot identify image file './data/cifar10/test/bird/0002.png'"
          ]
        }
      ],
      "metadata": {
        "id": "piL2aaprXDV1"
      }
    }
  ]
}